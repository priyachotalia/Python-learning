{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Priya Chotalia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes methods are a set of supervised learning algorithms based on applying Bayes' theorem with the \"naive\" assumption of conditional independence between every pair of features given the value of the class variable. Bayes'theorem states the following relationship, given class variable $y$ and dependent feature vector $x_1$ through $x_n$,:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(y \\mid x_1, \\dots, x_n) = \\frac{P(y) P(x_1, \\dots x_n \\mid y)}\n",
    "                                 {P(x_1, \\dots, x_n)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the naive conditional independence assumption, we have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\begin{align}\\begin{aligned}P(y \\mid x_1, \\dots, x_n) \\propto P(y) \\prod_{i=1}^{n} P(x_i \\mid y)\\\\\\Downarrow\\\\\\hat{y} = \\arg\\max_y P(y) \\prod_{i=1}^{n} P(x_i \\mid y),\\end{aligned}\\end{align}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can use Maximum A Posteriori (MAP) estimation to estimate $P(y)$ and $P(x_i \\mid y)$; the former is then the relative frequency of class $y$ in the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*References*:\n",
    "H. Zhang (2004). The optimality of Naive Bayes. Proc. FLAIRS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[GaussianNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html#sklearn.naive_bayes.GaussianNB) implements the Gaussian Naive Bayes algorithm for classification on the data sets where features are continuous.   \n",
    "The likelihood of the features is assumed to be Gaussian:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(x_i \\mid y) = \\frac{1}{\\sqrt{2\\pi\\sigma^2_y}} \\exp\\left(-\\frac{(x_i - \\mu_y)^2}{2\\sigma^2_y}\\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters $\\sigma_y$ and $\\mu_y$  are estimated using maximum likelihood."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Demo\n",
    "In this demo, we show how to build a Gaussian Naive Bayes classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate a synthetica 2D dataset\n",
    "X, y = make_classification(n_samples=50, n_features=2, n_informative=2,\n",
    "                           n_redundant=0, n_classes=3, n_clusters_per_class=1, \n",
    "                           weights=None, flip_y=0.01, class_sep=0.5, hypercube=True,\n",
    "                           shift=0.0, scale=1.0, shuffle=True, random_state=42)\n",
    "\n",
    "# Data split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42)\n",
    "\n",
    "# Visualize the generated data\n",
    "colors = ['blue', 'yellow', 'green']\n",
    "for i, color in enumerate(colors):\n",
    "    plt.scatter(X_train[y_train == i, 0], X_train[y_train == i, 1], c=color)\n",
    "plt.scatter(X_test[:, 0], X_test[:,1], c='red', marker='x', label='Testing Data')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy is: 0.8000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create and training a Gaussian Naive Bayes classifier model\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Use the model to predict testing data\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_pred, y_test)\n",
    "print('Testing accuracy is: %.4f\\n' % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated probability of classess: \n",
      " [0.325 0.375 0.3  ]\n",
      "Estimated mean for each Gaussian distribution: \n",
      " [[ 0.609  -0.5612]\n",
      " [ 0.3967  0.513 ]\n",
      " [-0.4016 -0.8369]]\n",
      "Estimated variance for each Gaussian distribution: \n",
      " [[0.2323 1.0484]\n",
      " [0.9352 0.0663]\n",
      " [0.331  0.6756]]\n"
     ]
    }
   ],
   "source": [
    "# Explore the learned probability (model parameters)\n",
    "print('Estimated probability of classess: \\n', clf.class_prior_)\n",
    "print('Estimated mean for each Gaussian distribution: \\n', clf.theta_)\n",
    "print('Estimated variance for each Gaussian distribution: \\n', clf.sigma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, for Class 0 and the first feature, we can have the following Gaussian disribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(x_0 \\mid Class=0) = \\frac{1}{\\sqrt{2\\pi\\cdot0.2323}} \\exp\\left(-\\frac{(x_0 - 0.6090)^2}{2\\cdot0.2323}\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes accuracy range: [0.3333, 1.0000]; mean: 0.6967; std: 0.1773\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Use 10-fold cross validation to show a more robust prediction accuracy\n",
    "clf = GaussianNB()\n",
    "scores = cross_val_score(clf, X, y, scoring='accuracy', cv=10)\n",
    "print('Gaussian Naive Bayes accuracy range: [%.4f, %.4f]; mean: %.4f; std: %.4f\\n' % (scores.min(), scores.max(), scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tasks** - The training data is generated as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Means estaimated manually: \n",
      " [[-2.     -1.3333]\n",
      " [ 2.      1.3333]]\n",
      "Variances estaimated manually: \n",
      " [[0.6667 0.2222]\n",
      " [0.6667 0.2222]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n",
    "y = np.array([1, 1, 1, 2, 2, 2])\n",
    "\n",
    "# Firstly, let's do the parameter estimation manually without using the model\n",
    "X_0_C_1=X[y==1][:,0]\n",
    "X_1_C_1=X[y==1][:,1]\n",
    "X_0_C_2=X[y==2][:,0]\n",
    "X_1_C_2=X[y==2][:,1]\n",
    "\n",
    "manual_means = np.array([[X_0_C_1.mean(), X_1_C_1.mean()], [X_0_C_2.mean(), X_1_C_2.mean()]])\n",
    "np.set_printoptions(precision=4)\n",
    "print('Means estaimated manually: \\n', manual_means)\n",
    "manual_vars = np.array([[X_0_C_1.var(), X_1_C_1.var()], [X_0_C_2.var(), X_1_C_2.var()]])\n",
    "print('Variances estaimated manually: \\n', manual_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q1**: Training a GaussianNB model and print out the learned model parameters (parameters of probability distributions). And check if the learned parameters comply with the manually estimated ones as shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated means: \n",
      " [[-2.     -1.3333]\n",
      " [ 2.      1.3333]]\n",
      "Estimated variance: \n",
      " [[0.6667 0.2222]\n",
      " [0.6667 0.2222]]\n"
     ]
    }
   ],
   "source": [
    "# Create and training a Gaussian Naive Bayes classifier model\n",
    "clf = GaussianNB()\n",
    "clf.fit(X, y)\n",
    "\n",
    "print('Estimated means: \\n', clf.theta_)\n",
    "print('Estimated variance: \\n', clf.sigma_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer to Q1**: \n",
    "\n",
    "Estimated means: \n",
    " [[-2.     -1.3333]\n",
    " [ 2.      1.3333]]\n",
    "Estimated variance: \n",
    " [[0.6667 0.2222]\n",
    " [0.6667 0.2222]]\n",
    " \n",
    " Yes. It complies with the ones estimated by hand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q2**: Predict the label of a data [-0.8,-1]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label is: 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_new = [[-0.8,-1]]\n",
    "y_pred = clf.predict(X_new)\n",
    "print('Class label is: %.f\\n' % y_pred[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer to Q2**: 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [MultinomialNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB) classification model is suitable for classification with discrete features. To let the model handle to categorical data, we often need to transform the categorical values to numberic ones, through [encoding](https://scikit-learn.org/stable/modules/preprocessing.html#encoding-categorical-features) methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Outlook Humidity    Wind Play\n",
      "0     Sunny     High    Weak   No\n",
      "1     Sunny     High  Strong   No\n",
      "2  Overcast     High    Weak  Yes\n",
      "3      Rain     High    Weak  Yes\n",
      "4      Rain   Normal    Weak  Yes\n",
      "\n",
      "Data shape:  (14, 4)\n"
     ]
    }
   ],
   "source": [
    "# Load the weather data\n",
    "weather_data = pd.read_csv('weather.csv')\n",
    "print(weather_data.head())\n",
    "print('\\nData shape: ', weather_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data pre-processing and preparation\n",
    "# Firstly, we need to convert the date from being categorical to being numerical\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "enc = OrdinalEncoder()\n",
    "coded_data = enc.fit_transform(weather_data)\n",
    "\n",
    "X = coded_data[:, 0:-1]\n",
    "y = coded_data[:, -1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creat and train a model\n",
    "clf_mnb = MultinomialNB()\n",
    "clf_mnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is: 0.7500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "y_pred = clf_mnb.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy is: %.4f\\n' % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated probability of classess: \n",
      " [0.4 0.6]\n",
      "Estimated class-conditional probabilities for each feature: \n",
      " [[0.6364 0.1818 0.1818]\n",
      " [0.4118 0.2941 0.2941]]\n"
     ]
    }
   ],
   "source": [
    "# Explore the learned model parameters (probabilities)\n",
    "# Note that the probabilities are in the logorithmic form. Why? The log-sum-exp trick for underflow of probability products\n",
    "print('Estimated probability of classess: \\n', np.e**clf_mnb.class_log_prior_)\n",
    "print('Estimated class-conditional probabilities for each feature: \\n', np.e**clf_mnb.feature_log_prob_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tasks** - The training data is generated as follows. The number of data instances (6) is small while the demensionality of the data is relatively highly (100)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.random.randint(5, size=(6, 100))\n",
    "y = np.array([1, 2, 3, 4, 5, 6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q3**: Training a MultinomialNB model, and predict the label of a data X_new = [[1,2,1,0,2,3,0,3,2,1,1,3,3,0,4,2,2,0,0,2,2,3,4,4,4,4,0,3,3,\n",
    "          1,1,1,2,3,1,3,0,2,2,0,4,2,4,3,2,0,1,1,1,2,3,0,0,3,4,3,3,4,\n",
    "          2,1,0,0,0,0,4,1,2,0,0,4,4,0,4,1,3,1,1,1,3,1,1,1,4,3,1,1,3,\n",
    "          2,0,0,0,3,4,1,1,4,3,2,3,4]]:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training a MultinomialNB model\n",
    "clf_mnb = MultinomialNB()\n",
    "clf_mnb.fit(X, y)\n",
    "\n",
    "#print('Estimated probability of classess: \\n', np.e**clf_mnb.class_log_prior_)\n",
    "#print('Estimated class-conditional probabilities for each feature: \\n', np.e**clf_mnb.feature_log_prob_)\n",
    "\n",
    "# Predict the class of the new data instance\n",
    "#X_new = np.random.randint(5, size=(1, 100))\n",
    "X_new = [[1,2,1,0,2,3,0,3,2,1,1,3,3,0,4,2,2,0,0,2,2,3,4,4,4,4,0,3,3,\n",
    "          1,1,1,2,3,1,3,0,2,2,0,4,2,4,3,2,0,1,1,1,2,3,0,0,3,4,3,3,4,\n",
    "          2,1,0,0,0,0,4,1,2,0,0,4,4,0,4,1,3,1,1,1,3,1,1,1,4,3,1,1,3,\n",
    "          2,0,0,0,3,4,1,1,4,3,2,3,4]]\n",
    "clf_mnb.predict(X_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer to Q3**: Can be any number in {1, 2, 3, 4, 5, 6}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4**: In our lecture, we discussed that if there is no occurence of some feature values, zero probabilities will appear. To overcome this issue, Laplace correction (smoothing) is proposed, as shown in the follow formula. In the [MultinomialNB](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB) implementation, the parameter 'alpha' controls the way we apply Laplace smoothing. The default value is 'alpha=1.0'. Please create and train a model with no Laplace smoothing for the above data set. Compare the leaned model parameters (probabilities) with the case 'alpha=1', by checking if there are zero probabilities (note that due to the accuracy issue, zero might be represented as a signficantly small number by the computer)\n",
    "$$p(x_{yi}|y)=\\frac{N_{yi}+\\alpha}{N_y+{\\alpha}n}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated probability of classess: \n",
      " [0.1667 0.1667 0.1667 0.1667 0.1667 0.1667]\n",
      "Estimated class-conditional probabilities for each feature: \n",
      " [[1.5464e-02 1.5464e-02 5.1546e-03 1.5464e-02 1.5464e-02 2.0619e-02\n",
      "  1.0309e-02 2.0619e-02 5.1546e-13 1.5464e-02 1.5464e-02 1.0309e-02\n",
      "  2.0619e-02 1.5464e-02 2.0619e-02 1.5464e-02 1.5464e-02 1.0309e-02\n",
      "  1.5464e-02 1.0309e-02 5.1546e-13 5.1546e-13 1.5464e-02 2.0619e-02\n",
      "  2.0619e-02 5.1546e-13 1.5464e-02 5.1546e-13 5.1546e-13 5.1546e-13\n",
      "  5.1546e-03 1.0309e-02 5.1546e-03 1.5464e-02 1.0309e-02 2.0619e-02\n",
      "  2.0619e-02 5.1546e-13 1.0309e-02 5.1546e-13 5.1546e-13 5.1546e-03\n",
      "  5.1546e-03 2.0619e-02 1.5464e-02 5.1546e-13 1.0309e-02 2.0619e-02\n",
      "  2.0619e-02 5.1546e-03 5.1546e-13 1.0309e-02 1.5464e-02 2.0619e-02\n",
      "  1.5464e-02 5.1546e-03 1.0309e-02 1.5464e-02 5.1546e-13 5.1546e-03\n",
      "  1.5464e-02 2.0619e-02 1.5464e-02 5.1546e-03 1.0309e-02 5.1546e-03\n",
      "  5.1546e-03 5.1546e-13 5.1546e-13 5.1546e-13 1.5464e-02 5.1546e-13\n",
      "  2.0619e-02 1.5464e-02 2.0619e-02 5.1546e-13 2.0619e-02 5.1546e-13\n",
      "  5.1546e-13 2.0619e-02 5.1546e-13 2.0619e-02 5.1546e-13 1.5464e-02\n",
      "  5.1546e-03 5.1546e-13 1.5464e-02 5.1546e-13 1.0309e-02 5.1546e-03\n",
      "  5.1546e-03 5.1546e-13 5.1546e-13 1.5464e-02 2.0619e-02 5.1546e-13\n",
      "  1.0309e-02 2.0619e-02 5.1546e-03 5.1546e-03]\n",
      " [5.5249e-13 2.2099e-02 2.2099e-02 5.5249e-03 1.6575e-02 1.6575e-02\n",
      "  1.1050e-02 1.6575e-02 1.1050e-02 2.2099e-02 5.5249e-03 5.5249e-13\n",
      "  5.5249e-03 5.5249e-13 2.2099e-02 1.6575e-02 5.5249e-03 1.1050e-02\n",
      "  1.6575e-02 5.5249e-03 5.5249e-03 1.1050e-02 5.5249e-13 5.5249e-13\n",
      "  1.6575e-02 1.6575e-02 1.6575e-02 1.6575e-02 1.6575e-02 5.5249e-03\n",
      "  5.5249e-03 2.2099e-02 5.5249e-13 1.1050e-02 5.5249e-03 2.2099e-02\n",
      "  2.2099e-02 5.5249e-03 5.5249e-03 1.6575e-02 5.5249e-03 5.5249e-03\n",
      "  5.5249e-13 5.5249e-03 1.6575e-02 2.2099e-02 2.2099e-02 1.6575e-02\n",
      "  5.5249e-03 1.1050e-02 1.1050e-02 1.1050e-02 5.5249e-13 1.1050e-02\n",
      "  1.6575e-02 5.5249e-13 1.1050e-02 5.5249e-13 5.5249e-03 5.5249e-13\n",
      "  5.5249e-03 1.6575e-02 2.2099e-02 1.1050e-02 5.5249e-13 1.6575e-02\n",
      "  5.5249e-03 1.1050e-02 2.2099e-02 5.5249e-03 5.5249e-13 5.5249e-13\n",
      "  5.5249e-13 1.6575e-02 5.5249e-13 5.5249e-13 1.1050e-02 1.1050e-02\n",
      "  5.5249e-03 2.2099e-02 5.5249e-13 2.2099e-02 1.1050e-02 1.1050e-02\n",
      "  5.5249e-03 1.6575e-02 1.6575e-02 1.1050e-02 5.5249e-03 5.5249e-03\n",
      "  5.5249e-13 1.6575e-02 5.5249e-13 1.6575e-02 5.5249e-13 5.5249e-03\n",
      "  1.6575e-02 1.6575e-02 1.1050e-02 5.5249e-13]\n",
      " [9.9010e-03 1.4851e-02 4.9505e-03 9.9010e-03 4.9505e-13 9.9010e-03\n",
      "  1.4851e-02 4.9505e-13 1.4851e-02 1.9802e-02 9.9010e-03 1.9802e-02\n",
      "  9.9010e-03 1.9802e-02 9.9010e-03 4.9505e-03 4.9505e-03 1.4851e-02\n",
      "  1.9802e-02 4.9505e-13 9.9010e-03 9.9010e-03 1.9802e-02 4.9505e-03\n",
      "  9.9010e-03 1.4851e-02 1.9802e-02 9.9010e-03 1.4851e-02 4.9505e-03\n",
      "  1.4851e-02 9.9010e-03 4.9505e-03 1.4851e-02 1.4851e-02 4.9505e-03\n",
      "  1.4851e-02 1.4851e-02 1.9802e-02 1.4851e-02 1.9802e-02 4.9505e-03\n",
      "  4.9505e-03 9.9010e-03 9.9010e-03 4.9505e-03 1.4851e-02 4.9505e-13\n",
      "  4.9505e-03 1.4851e-02 1.4851e-02 4.9505e-03 4.9505e-13 1.9802e-02\n",
      "  1.4851e-02 1.4851e-02 1.4851e-02 9.9010e-03 4.9505e-13 1.9802e-02\n",
      "  1.9802e-02 1.4851e-02 1.9802e-02 9.9010e-03 4.9505e-03 1.4851e-02\n",
      "  9.9010e-03 1.4851e-02 4.9505e-03 9.9010e-03 4.9505e-03 4.9505e-13\n",
      "  4.9505e-13 1.9802e-02 9.9010e-03 4.9505e-13 1.9802e-02 4.9505e-13\n",
      "  4.9505e-13 4.9505e-13 1.4851e-02 4.9505e-13 1.4851e-02 1.4851e-02\n",
      "  4.9505e-13 9.9010e-03 9.9010e-03 9.9010e-03 9.9010e-03 1.9802e-02\n",
      "  4.9505e-13 4.9505e-03 1.9802e-02 4.9505e-13 4.9505e-13 9.9010e-03\n",
      "  1.4851e-02 4.9505e-03 4.9505e-13 4.9505e-13]\n",
      " [2.0202e-02 5.0505e-13 5.0505e-03 2.0202e-02 5.0505e-03 5.0505e-03\n",
      "  5.0505e-13 5.0505e-13 2.0202e-02 1.0101e-02 2.0202e-02 1.5152e-02\n",
      "  5.0505e-13 1.0101e-02 1.0101e-02 5.0505e-03 5.0505e-13 5.0505e-03\n",
      "  5.0505e-13 2.0202e-02 1.0101e-02 5.0505e-13 1.0101e-02 5.0505e-13\n",
      "  2.0202e-02 1.0101e-02 5.0505e-03 1.0101e-02 5.0505e-03 1.0101e-02\n",
      "  2.0202e-02 1.5152e-02 1.0101e-02 2.0202e-02 2.0202e-02 2.0202e-02\n",
      "  5.0505e-13 5.0505e-13 1.5152e-02 5.0505e-03 1.5152e-02 2.0202e-02\n",
      "  1.0101e-02 5.0505e-03 1.5152e-02 5.0505e-03 5.0505e-03 1.0101e-02\n",
      "  5.0505e-03 1.0101e-02 5.0505e-13 5.0505e-03 5.0505e-13 1.5152e-02\n",
      "  1.0101e-02 5.0505e-13 5.0505e-13 1.5152e-02 5.0505e-03 5.0505e-03\n",
      "  1.5152e-02 1.5152e-02 5.0505e-03 1.5152e-02 1.0101e-02 2.0202e-02\n",
      "  2.0202e-02 5.0505e-13 2.0202e-02 1.0101e-02 1.5152e-02 2.0202e-02\n",
      "  1.0101e-02 1.0101e-02 5.0505e-13 1.0101e-02 2.0202e-02 5.0505e-13\n",
      "  2.0202e-02 5.0505e-03 2.0202e-02 2.0202e-02 2.0202e-02 1.5152e-02\n",
      "  2.0202e-02 1.0101e-02 5.0505e-03 1.5152e-02 2.0202e-02 1.5152e-02\n",
      "  5.0505e-13 1.0101e-02 5.0505e-13 5.0505e-03 1.0101e-02 1.0101e-02\n",
      "  5.0505e-13 2.0202e-02 5.0505e-13 5.0505e-03]\n",
      " [5.1813e-13 5.1813e-03 2.0725e-02 5.1813e-03 1.0363e-02 5.1813e-03\n",
      "  1.5544e-02 1.5544e-02 1.0363e-02 1.0363e-02 5.1813e-03 5.1813e-13\n",
      "  1.5544e-02 2.0725e-02 2.0725e-02 1.5544e-02 1.0363e-02 5.1813e-03\n",
      "  2.0725e-02 1.5544e-02 1.0363e-02 2.0725e-02 5.1813e-13 5.1813e-03\n",
      "  5.1813e-13 1.0363e-02 5.1813e-13 1.0363e-02 5.1813e-03 2.0725e-02\n",
      "  1.0363e-02 2.0725e-02 5.1813e-13 5.1813e-03 2.0725e-02 2.0725e-02\n",
      "  1.5544e-02 2.0725e-02 1.5544e-02 2.0725e-02 5.1813e-13 1.5544e-02\n",
      "  1.5544e-02 2.0725e-02 1.0363e-02 5.1813e-13 2.0725e-02 5.1813e-13\n",
      "  1.5544e-02 2.0725e-02 1.0363e-02 5.1813e-03 5.1813e-13 1.0363e-02\n",
      "  1.5544e-02 5.1813e-03 2.0725e-02 5.1813e-13 1.5544e-02 5.1813e-13\n",
      "  5.1813e-13 2.0725e-02 1.0363e-02 1.5544e-02 5.1813e-13 5.1813e-03\n",
      "  1.5544e-02 5.1813e-03 2.0725e-02 5.1813e-03 1.0363e-02 5.1813e-13\n",
      "  5.1813e-03 1.0363e-02 5.1813e-13 5.1813e-03 5.1813e-03 5.1813e-13\n",
      "  5.1813e-03 5.1813e-13 5.1813e-13 1.5544e-02 1.5544e-02 5.1813e-03\n",
      "  5.1813e-13 5.1813e-13 2.0725e-02 2.0725e-02 1.5544e-02 5.1813e-13\n",
      "  5.1813e-03 5.1813e-03 1.0363e-02 5.1813e-03 1.5544e-02 1.5544e-02\n",
      "  5.1813e-03 1.0363e-02 2.0725e-02 1.0363e-02]\n",
      " [2.0408e-02 1.0204e-02 1.5306e-02 1.5306e-02 1.5306e-02 2.0408e-02\n",
      "  5.1020e-13 5.1020e-03 5.1020e-03 1.0204e-02 2.0408e-02 1.5306e-02\n",
      "  1.0204e-02 1.5306e-02 5.1020e-13 1.5306e-02 5.1020e-03 5.1020e-13\n",
      "  1.5306e-02 5.1020e-13 5.1020e-03 5.1020e-03 2.0408e-02 2.0408e-02\n",
      "  1.5306e-02 1.0204e-02 2.0408e-02 1.5306e-02 2.0408e-02 2.0408e-02\n",
      "  1.0204e-02 1.0204e-02 5.1020e-03 2.0408e-02 1.0204e-02 5.1020e-03\n",
      "  5.1020e-13 1.5306e-02 2.0408e-02 2.0408e-02 1.0204e-02 1.5306e-02\n",
      "  5.1020e-13 2.0408e-02 5.1020e-13 5.1020e-13 2.0408e-02 5.1020e-13\n",
      "  1.0204e-02 2.0408e-02 1.5306e-02 1.0204e-02 1.5306e-02 1.0204e-02\n",
      "  5.1020e-13 5.1020e-13 5.1020e-03 2.0408e-02 1.0204e-02 5.1020e-03\n",
      "  5.1020e-03 5.1020e-13 5.1020e-13 5.1020e-03 1.5306e-02 5.1020e-13\n",
      "  5.1020e-13 1.5306e-02 1.0204e-02 1.0204e-02 5.1020e-13 1.0204e-02\n",
      "  1.0204e-02 5.1020e-13 1.5306e-02 5.1020e-13 1.0204e-02 5.1020e-03\n",
      "  5.1020e-13 5.1020e-13 5.1020e-03 2.0408e-02 5.1020e-13 2.0408e-02\n",
      "  2.0408e-02 1.0204e-02 1.5306e-02 1.0204e-02 5.1020e-03 5.1020e-13\n",
      "  5.1020e-13 1.0204e-02 1.5306e-02 5.1020e-13 2.0408e-02 5.1020e-03\n",
      "  1.5306e-02 1.0204e-02 2.0408e-02 1.0204e-02]]\n"
     ]
    }
   ],
   "source": [
    "# Create and train a MultinomialNB model with no Laplace smoothing\n",
    "clf_mnb = MultinomialNB(alpha=0)\n",
    "clf_mnb.fit(X, y)\n",
    "\n",
    "print('Estimated probability of classess: \\n', np.e**clf_mnb.class_log_prior_)\n",
    "print('Estimated class-conditional probabilities for each feature: \\n', np.e**clf_mnb.feature_log_prob_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer to Q4**: Yes, there are many zeros (x.xxx e-13). Zero probabilities occur due to the lack of attribute values, given that we only have 6 data instances, while we have 100 features and each has 5 possible values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Process on 'Iris' Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Week 9, we have studied how to use KNN algorithm to do classification task on 'iris' data. Here,we are going to employ the GaussianNB to conduct the same task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "iris_data = load_iris()\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris_data['data'], iris_data['target'], random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q4**ï¼šReport the prediction result on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is: 1.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "print('Accuracy is: %.4f\\n' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer to Q4**: Accuracy is 1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q5**: Compare the prediction accuaracy between KNN clasifier (use the optimal K you've identied) and Gaussian Naive Bayes. Use 10-cross validation to report the accuracy mean and standard deviation (Note this is to ensure the comparison is based on robust performace). Which classifidation mdoel is more accurate on Iris data set?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian Naive Bayes accuracy range: [0.8667, 1.0000]; mean: 0.9533; std: 0.0427\n",
      "\n",
      "KNN Classifier accuracy range: [0.9333, 1.0000]; mean: 0.9800; std: 0.0306\n",
      "\n",
      "t, p: -1.5240, 0.1449\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf_gnb = GaussianNB()\n",
    "clf_knn = KNeighborsClassifier(n_neighbors=13)\n",
    "\n",
    "scores = cross_val_score(clf_gnb, iris_data['data'], iris_data['target'], scoring='accuracy', cv=10)\n",
    "print('Gaussian Naive Bayes accuracy range: [%.4f, %.4f]; mean: %.4f; std: %.4f\\n'\n",
    "      % (scores.min(), scores.max(), scores.mean(), scores.std()))\n",
    "scores_gnb = scores\n",
    "\n",
    "scores = cross_val_score(clf_knn, iris_data['data'], iris_data['target'], scoring='accuracy', cv=10)\n",
    "print('KNN Classifier accuracy range: [%.4f, %.4f]; mean: %.4f; std: %.4f\\n'\n",
    "      % (scores.min(), scores.max(), scores.mean(), scores.std()))\n",
    "scores_knn = scores\n",
    "\n",
    "# This is to show t-test on their performances.\n",
    "from scipy.stats import ttest_ind\n",
    "t, p = ttest_ind(scores_gnb, scores_knn)\n",
    "print ('t, p: %.4f, %.4f\\n' % (t, p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer to Q5**: \n",
    "    \n",
    "Gaussian Naive Bayes accuracy range: [0.8667, 1.0000]; mean: 0.9533; std: 0.0427\n",
    "\n",
    "KNN Classifier accuracy range: [0.9333, 1.0000]; mean: 0.9800; std: 0.0306\n",
    "    \n",
    "The averaged accuracy of the K nearest neigthbors classifier is higher than that of the Naive Bayes classifier. But in terms of t-test, the two performances of the two classifiers are not statistically significantly different if we use the significance level 0.05, as the p value 0.1449 > 0.05."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q6**: Can we use Multinomial Naive Bayes classifiation model for Iris data? Yes! We can discretize continuous features by use the [KBinsDiscretizer](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.KBinsDiscretizer.html#sklearn.preprocessing.KBinsDiscretizer) method. Note that you can different ways of discrization. Please report the prediction result with the following discritization method. Also, try another discritization method with parameter 'encode=onehot', and report the prediction result. Use 10-cross validation to report the accuracy mean and standard deviation as we did above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy range with ordinal discretization: [0.4667, 0.8667]; mean: 0.7000; std: 0.1043\n",
      "\n",
      "Accuracy range with onehot discretization: [0.8000, 1.0000]; mean: 0.9200; std: 0.0653\n",
      "\n",
      "t, p: -5.3612, 0.00004278\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "encoder = KBinsDiscretizer(n_bins=5, encode='ordinal', strategy='uniform')\n",
    "X = encoder.fit_transform(iris_data['data'])\n",
    "y = iris_data['target']\n",
    "\n",
    "clf_mnb = MultinomialNB()\n",
    "scores = cross_val_score(clf_mnb, X, y, scoring='accuracy', cv=10)\n",
    "print('Accuracy range with ordinal discretization: [%.4f, %.4f]; mean: %.4f; std: %.4f\\n'\n",
    "      % (scores.min(), scores.max(), scores.mean(), scores.std()))\n",
    "scores_ordinal = scores\n",
    "\n",
    "encoder = KBinsDiscretizer(n_bins=5, encode='onehot', strategy='uniform')\n",
    "X = encoder.fit_transform(iris_data['data'])\n",
    "y = iris_data['target']\n",
    "clf_mnb = MultinomialNB()\n",
    "scores = cross_val_score(clf_mnb, X, y, scoring='accuracy', cv=10)\n",
    "print('Accuracy range with onehot discretization: [%.4f, %.4f]; mean: %.4f; std: %.4f\\n'\n",
    "      % (scores.min(), scores.max(), scores.mean(), scores.std()))\n",
    "scores_onehot = scores\n",
    "\n",
    "# This is to show t-test on their performances.\n",
    "from scipy.stats import ttest_ind\n",
    "t, p = ttest_ind(scores_ordinal, scores_onehot)\n",
    "print ('t, p: %.4f, %.8f\\n' % (t, p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer to Q6**:\n",
    "\n",
    "Accuracy range with ordinal discretization: [0.4667, 0.8667]; mean: 0.7000; std: 0.1043\n",
    "\n",
    "Accuracy range with onehot discretization: [0.8000, 1.0000]; mean: 0.9200; std: 0.0653\n",
    "\n",
    "The discretization with onehot encoding can be regarded much better than that with ordinal encoding. The p value 0.00004278 is much smaller than the commonly-used significance level 0.05."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Predict Human Activity Recognition (HAR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of this practice exercise is to predict current human activity based on phisiological activity measurements from 53 different features based in the [HAR dataset](http://groupware.les.inf.puc-rio.br/har#sbia_paper_section). The training (`har_train.csv`) and test (`har_validate.csv`) datasets are provided."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q7**: Build a Naive Bayes model, predict on the test dataset and compute the [confusion matrix](https://towardsdatascience.com/understanding-confusion-matrix-a9ad42dcfd62). Note: Please refer to the [`sklearn.metrics.confusion_matrix`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html). This is a check point question for this week's workshop. You need to report accuracy_scores on train and test set of Human Activity Recognition dataset. Also provide confusion matrix on test set and provide a brief interpretation of your results based on accuracy scores and confusion matrix (which class is misclassified into what). Your description should not be more than a paragraph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "har_train = pd.read_csv(\"har_train.csv\")\n",
    "har_test = pd.read_csv(\"har_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape:  (13737, 53)\n",
      "test shape:  (5885, 53)\n",
      "  classe  roll_belt  pitch_belt  yaw_belt  total_accel_belt  gyros_belt_x  \\\n",
      "0      A       1.41        8.07     -94.4                 3          0.00   \n",
      "1      A       1.41        8.07     -94.4                 3          0.02   \n",
      "2      A       1.42        8.07     -94.4                 3          0.00   \n",
      "3      A       1.48        8.05     -94.4                 3          0.02   \n",
      "4      A       1.45        8.06     -94.4                 3          0.02   \n",
      "\n",
      "   gyros_belt_y  gyros_belt_z  accel_belt_x  accel_belt_y  ...  \\\n",
      "0           0.0         -0.02           -21             4  ...   \n",
      "1           0.0         -0.02           -22             4  ...   \n",
      "2           0.0         -0.02           -20             5  ...   \n",
      "3           0.0         -0.03           -22             3  ...   \n",
      "4           0.0         -0.02           -21             4  ...   \n",
      "\n",
      "   total_accel_forearm  gyros_forearm_x  gyros_forearm_y  gyros_forearm_z  \\\n",
      "0                   36             0.03             0.00            -0.02   \n",
      "1                   36             0.02             0.00            -0.02   \n",
      "2                   36             0.03            -0.02             0.00   \n",
      "3                   36             0.02            -0.02             0.00   \n",
      "4                   36             0.02            -0.02            -0.03   \n",
      "\n",
      "   accel_forearm_x  accel_forearm_y  accel_forearm_z  magnet_forearm_x  \\\n",
      "0              192              203             -215               -17   \n",
      "1              192              203             -216               -18   \n",
      "2              196              204             -213               -18   \n",
      "3              189              206             -214               -16   \n",
      "4              193              203             -215                -9   \n",
      "\n",
      "   magnet_forearm_y  magnet_forearm_z  \n",
      "0               654               476  \n",
      "1               661               473  \n",
      "2               658               469  \n",
      "3               658               469  \n",
      "4               660               478  \n",
      "\n",
      "[5 rows x 53 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"train shape: \", har_train.shape)\n",
    "print(\"test shape: \", har_test.shape)\n",
    "print(har_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['classe', 'roll_belt', 'pitch_belt', 'yaw_belt', 'total_accel_belt',\n",
      "       'gyros_belt_x', 'gyros_belt_y', 'gyros_belt_z', 'accel_belt_x',\n",
      "       'accel_belt_y', 'accel_belt_z', 'magnet_belt_x', 'magnet_belt_y',\n",
      "       'magnet_belt_z', 'roll_arm', 'pitch_arm', 'yaw_arm', 'total_accel_arm',\n",
      "       'gyros_arm_x', 'gyros_arm_y', 'gyros_arm_z', 'accel_arm_x',\n",
      "       'accel_arm_y', 'accel_arm_z', 'magnet_arm_x', 'magnet_arm_y',\n",
      "       'magnet_arm_z', 'roll_dumbbell', 'pitch_dumbbell', 'yaw_dumbbell',\n",
      "       'total_accel_dumbbell', 'gyros_dumbbell_x', 'gyros_dumbbell_y',\n",
      "       'gyros_dumbbell_z', 'accel_dumbbell_x', 'accel_dumbbell_y',\n",
      "       'accel_dumbbell_z', 'magnet_dumbbell_x', 'magnet_dumbbell_y',\n",
      "       'magnet_dumbbell_z', 'roll_forearm', 'pitch_forearm', 'yaw_forearm',\n",
      "       'total_accel_forearm', 'gyros_forearm_x', 'gyros_forearm_y',\n",
      "       'gyros_forearm_z', 'accel_forearm_x', 'accel_forearm_y',\n",
      "       'accel_forearm_z', 'magnet_forearm_x', 'magnet_forearm_y',\n",
      "       'magnet_forearm_z'],\n",
      "      dtype='object')\n",
      "\n",
      " {'B', 'D', 'A', 'C', 'E'}\n"
     ]
    }
   ],
   "source": [
    "# checking all 53 column names in the dataset\n",
    "print(har_train.columns)\n",
    "\n",
    "# The variable to predict (or label) is \"classe\" column. \n",
    "# checking number of classes in classe column\n",
    "print(\"\\n\",set(har_train['classe']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (13737, 52)\n",
      "y_train shape:  (13737,)\n",
      "X_test shape:  (5885, 52)\n",
      "y_test shape:  (5885,)\n"
     ]
    }
   ],
   "source": [
    "# Separate features and class labels\n",
    "X_train = har_train.drop(['classe'], axis=1)\n",
    "y_train = har_train['classe']\n",
    "X_test = har_test.drop(['classe'], axis=1)\n",
    "y_test = har_test['classe']\n",
    "print(\"X_train shape: \", X_train.shape)\n",
    "print(\"y_train shape: \", y_train.shape)\n",
    "print(\"X_test shape: \", X_test.shape)\n",
    "print(\"y_test shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and train the model\n",
    "gnb_clf = GaussianNB()\n",
    "gnb_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on train set: 0.5581\n",
      "Accuracy on test set: 0.5543\n",
      "[[1070   95  262  212   35]\n",
      " [ 127  685  145   76  106]\n",
      " [ 223  106  512  136   49]\n",
      " [ 102   35  271  441  115]\n",
      " [  51  239   95  143  554]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reporting accuracy score and confusion matrix on test set\n",
    "y_pred_train = gnb_clf.predict(X_train)\n",
    "y_pred_test = gnb_clf.predict(X_test)\n",
    "print(\"Accuracy on train set: %.4f\" % accuracy_score(y_train, y_pred_train))\n",
    "print(\"Accuracy on test set: %.4f\" % accuracy_score(y_test, y_pred_test))\n",
    "labels = ['A', 'B', 'C', 'D', 'E']\n",
    "cm = confusion_matrix(y_test, y_pred_test, labels)\n",
    "print(cm)\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "cax = ax.matshow(cm)\n",
    "plt.title('Confusion matrix on test set')\n",
    "fig.colorbar(cax)\n",
    "ax.set_xticklabels([''] + labels)\n",
    "ax.set_yticklabels([''] + labels)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
